{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: Steps for the Chest X-Ray Classification Project\n",
    "\n",
    "This project aims to develop a Convolutional Neural Network (CNN) for binary classification of chest X-ray images (normal vs pneumonia). The following are the key steps to complete this project:\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Setup and Environment\n",
    "1. Import necessary libraries (TensorFlow, Keras, etc.).\n",
    "2. Verify the environment setup in JupyterLab.\n",
    "3. Set up paths for the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Dataset Preprocessing\n",
    "1. Load images from dataset directories (`train`, `val`, `test`) and their corresponding labels.\n",
    "2. Resize images to a consistent size for the CNN input.\n",
    "3. Normalize pixel values for faster convergence.\n",
    "4. Apply data augmentation to the training set (e.g., rotations, flips, zooms).\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Building the CNN\n",
    "1. Design a CNN model with convolutional and pooling layers.\n",
    "2. Use dropout and/or regularization to reduce overfitting.\n",
    "3. Compile the model with appropriate loss, optimizer, and metrics (accuracy, sensitivity, specificity).\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Training the Model\n",
    "1. Use data generators for training and validation sets.\n",
    "2. Train the model for a sufficient number of epochs.\n",
    "3. Use early stopping or checkpoints to prevent overfitting.\n",
    "4. Monitor performance metrics during training.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5: Evaluation\n",
    "1. Evaluate the model on the test set.\n",
    "2. Plot accuracy and loss curves for training and validation.\n",
    "3. Generate a classification report (precision, recall, F1-score).\n",
    "4. Plot the confusion matrix.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 6: Fine-Tuning\n",
    "1. Adjust model hyperparameters (e.g., learning rate, number of layers).\n",
    "2. Apply transfer learning with a pre-trained model if needed.\n",
    "3. Re-train the model to achieve the target metrics (90% sensitivity and 90% specificity).\n",
    "\n",
    "---\n",
    "\n",
    "## Step 7: Final Analysis and Documentation\n",
    "1. Summarize the modelâ€™s performance.\n",
    "2. Compare results against the target metrics.\n",
    "3. Document the process and findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setup and Environment\n",
    "\n",
    "In this step, we will:\n",
    "1. Import the required libraries for data preprocessing, model creation, and evaluation.\n",
    "2. Verify the environment to ensure the required tools are installed.\n",
    "3. Set up paths for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\jorga\\AppData\\Local\\Temp\\ipykernel_24376\\2298472964.py:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  base_dir = \"..\\data\\chest_xray\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "Train directory exists: True\n",
      "Test directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Verify TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set up dataset paths\n",
    "base_dir = \"..\\data\\chest_xray\"  \n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")  # Keep only train and test directories\n",
    "\n",
    "# Check if directories exist\n",
    "print(\"Train directory exists:\", os.path.exists(train_dir))\n",
    "print(\"Test directory exists:\", os.path.exists(test_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Dataset Preprocessing\n",
    "\n",
    "In this step, we will:\n",
    "1. Load and preprocess images from the dataset.\n",
    "2. Standardize the input size and normalize pixel values.\n",
    "3. Apply data augmentation to the training set for better generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Load images from directories\u001b[39;00m\n\u001b[0;32m     21\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     22\u001b[0m     train_dir,\n\u001b[0;32m     23\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(IMG_HEIGHT, IMG_WIDTH),\n\u001b[0;32m     24\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     25\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Binary classification (normal/pneumonia)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m val_test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mval_dir\u001b[49m,\n\u001b[0;32m     30\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(IMG_HEIGHT, IMG_WIDTH),\n\u001b[0;32m     31\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     32\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     35\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m val_test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     36\u001b[0m     test_dir,\n\u001b[0;32m     37\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(IMG_HEIGHT, IMG_WIDTH),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Maintain order for evaluation\u001b[39;00m\n\u001b[0;32m     41\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Image dimensions\n",
    "IMG_HEIGHT, IMG_WIDTH = 150, 150\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,  # Random rotation\n",
    "    width_shift_range=0.2,  # Random horizontal shift\n",
    "    height_shift_range=0.2,  # Random vertical shift\n",
    "    shear_range=0.2,  # Shear transformations\n",
    "    zoom_range=0.2,  # Zoom\n",
    "    horizontal_flip=True,  # Flip images horizontally\n",
    "    fill_mode=\"nearest\"  # Fill in missing pixels\n",
    ")\n",
    "\n",
    "# Only rescaling for validation and test sets (no augmentation)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Load images from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\"  # Binary classification (normal/pneumonia)\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False  # Maintain order for evaluation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Step 2: Dataset Preprocessing\n",
    "\n",
    "In this step, we preprocess the chest X-ray images to prepare them for training, validation, and testing. Here's what each part of the code does:\n",
    "\n",
    "1. **Image Dimensions**:\n",
    "   - All images are resized to `150x150` pixels to ensure consistency across the dataset and compatibility with the CNN model.\n",
    "\n",
    "2. **Batch Size**:\n",
    "   - Images are processed in batches of 32 to efficiently load and train on data without exhausting memory.\n",
    "\n",
    "3. **Data Augmentation (Training Set)**:\n",
    "   - **`rescale=1.0 / 255`**: Normalizes pixel values to the range [0, 1] for faster convergence during training.\n",
    "   - **`rotation_range=20`**: Randomly rotates images within a range of `-20 degrees` to `+20 degrees`.\n",
    "   - **`width_shift_range=0.2` and `height_shift_range=0.2`**: Randomly shifts the image horizontally and vertically by up to 20% of the width/height.\n",
    "   - **`shear_range=0.2`**: Applies a shearing transformation to the image. This essentially shifts one part of the image more than another, creating a \"slanted\" version of the image. (https://youtube.com/shorts/-lXkrjeB6Ls?si=CIIeZJAzOI7CgN27)\n",
    "   - **`zoom_range=0.2`**: Randomly zooms in or out by up to 20%.\n",
    "   - **`horizontal_flip=True`**: Randomly flips images horizontally.\n",
    "   - **`fill_mode=\"nearest\"`**: Fills in any missing pixels after transformations with the nearest pixel values.\n",
    "\n",
    "4. **Validation and Test Sets**:\n",
    "   - Only pixel normalization (`rescale=1.0 / 255`) is applied. No augmentation is used to ensure these datasets represent real-world, unaltered data. Images have pixel values in the range [0, 255]. 0 represents black and 255 represents white. These values are too large for most neural network models to handle efficiently, as they can lead to slower convergence and unstable training. \n",
    "\n",
    "5. **Data Generators**:\n",
    "   - **`train_generator`**: Loads images from the `train` directory and applies augmentation.\n",
    "   - **`val_generator`**: Loads images from the `val` directory for validation without augmentation.\n",
    "   - **`test_generator`**: Loads images from the `test` directory for final evaluation, ensuring the images are not shuffled to maintain their order. Shuffle default value is True (so in training and validation it is gonna be shuffled)\n",
    "\n",
    "**Why Preprocessing is Important**:\n",
    "- **Data Augmentation**: Introduces variability in the training data, improving the modelâ€™s ability to generalize to unseen data.\n",
    "- **Normalization**: Scales pixel values to a uniform range, making training more efficient and stable.\n",
    "- **Batch Processing**: Loads data in chunks to optimize memory usage and speed up training.\n",
    "\n",
    "This preprocessing step ensures the model is trained on a well-prepared dataset, improving its performance and generalization ability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
